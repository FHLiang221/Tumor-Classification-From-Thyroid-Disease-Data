{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: category-encoders in /opt/anaconda3/lib/python3.12/site-packages (2.6.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: ray[tune] in /opt/anaconda3/lib/python3.12/site-packages (2.39.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (4.19.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (1.0.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (1.2.0)\n",
      "Requirement already satisfied: frozenlist in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (1.4.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (2.32.2)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (14.0.2)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from ray[tune]) (2024.3.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.14.0)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.30)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from category-encoders) (0.14.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from category-encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray[tune]) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray[tune]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray[tune]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray[tune]) (0.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->ray[tune]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->ray[tune]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->ray[tune]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->ray[tune]) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /opt/anaconda3/lib/python3.12/site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: scikit-plot in /opt/anaconda3/lib/python3.12/site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-plot) (3.9.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-plot) (1.4.2)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-plot) (1.14.1)\n",
      "Requirement already satisfied: joblib>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-plot) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Requirement already satisfied: kagglehub in /opt/anaconda3/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ray\\[tune\\] optuna scikit-learn xgboost category-encoders numpy pandas\n",
    "!pip install -U ipywidgets\n",
    "!pip install -U scipy\n",
    "!pip install scikit-plot\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune \n",
    "from sklearn.preprocessing import QuantileTransformer, OneHotEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from category_encoders import CatBoostEncoder\n",
    "import pandas as pd \n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune import trainable, with_parameters\n",
    "\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### UTILS FOR TESTING SCRIPT, Can Ignore####\n",
    "def make_rand_data(n_samples, n_num, n_cat): \n",
    "    \"\"\"\n",
    "    Make random data for testing purposes\n",
    "    \"\"\"\n",
    "    X = np.random.rand(n_samples, n_num)\n",
    "    X_cat = np.random.randint(0, 10, (n_samples, n_cat))\n",
    "    # Make y a function of X, and map to integers from 1-20\n",
    "    y = np.sum(X, axis=1)\n",
    "    y = y + X_cat[:, 1]\n",
    "    y = y - (X_cat[:, 2] * X_cat[:, 3])    \n",
    "    y = np.digitize(y, bins=np.linspace(0, 20, 5))\n",
    "    return X, X_cat, y\n",
    "\n",
    "def make_rand_df(n_samples, n_num, n_cat):\n",
    "    \"\"\"\n",
    "    Make random dataframe for testing purposes\n",
    "    \"\"\"\n",
    "    X, X_cat, y = make_rand_data(n_samples, n_num, n_cat)\n",
    "    df = pd.DataFrame(X, columns=[f\"num_{i}\" for i in range(n_num)])\n",
    "    df_cat = pd.DataFrame(X_cat, columns=[f\"cat_{i}\" for i in range(n_cat)])\n",
    "    df[\"target\"] = y\n",
    "    return pd.concat([df, df_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downcast the datatypes of a numpy array to save memory\n",
    "    \"\"\"\n",
    "    arr = arr.copy()\n",
    "    for i in range(arr.shape[1]):\n",
    "        # Check if column is int, float or object\n",
    "        # For floats, check min & max, downcast to float32 if possible\n",
    "        # For ints, check min & max, downcast to int8 if possible\n",
    "        if arr[:, i].dtype == \"int64\":\n",
    "            if np.all(arr[:, i] == arr[:, i].astype(\"int8\")):\n",
    "                arr[:, i] = arr[:, i].astype(\"int8\")\n",
    "            elif np.all(arr[:, i] == arr[:, i].astype(\"int16\")):\n",
    "                arr[:, i] = arr[:, i].astype(\"int16\")\n",
    "            elif np.all(arr[:, i] == arr[:, i].astype(\"int32\")):\n",
    "                arr[:, i] = arr[:, i].astype(\"int32\")\n",
    "        if arr[:, i].dtype == \"float64\":\n",
    "            if np.allclose(arr[:, i], arr[:, i].astype(\"float32\"), atol=1e-5):\n",
    "                arr[:, i] = arr[:, i].astype(\"float32\")\n",
    "    return arr\n",
    "\n",
    "\n",
    "def preprocess_df(df, numerical_columns, categorical_columns, target_column, train_pct=0.8):\n",
    "    # Encode the target column\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[target_column] = label_encoder.fit_transform(df[target_column])  # Converts 'T2', 'T3a', etc., into integers\n",
    "    \n",
    "    # Split the data\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Ensure `y` is a Pandas Series\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y, name=target_column)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_pct, random_state=42)\n",
    "\n",
    "    # Validate types of `y_train`\n",
    "    if not isinstance(y_train, pd.Series):\n",
    "        print(f\"Converting y_train to Pandas Series\")\n",
    "        y_train = pd.Series(y_train, index=X_train.index, name=target_column)\n",
    "    \n",
    "    # Split numerical and categorical columns\n",
    "    x_num_train = X_train[numerical_columns].values\n",
    "    x_num_test = X_test[numerical_columns].values\n",
    "    x_cat_train = X_train[categorical_columns]\n",
    "    x_cat_test = X_test[categorical_columns]\n",
    "\n",
    "    # Debugging output for inputs\n",
    "    print(\"Debugging Input Types:\")\n",
    "    print(f\"Type of x_cat_train: {type(x_cat_train)}\")\n",
    "    print(f\"Type of y_train: {type(y_train)}\")\n",
    "    print(f\"First few values of y_train:\\n{y_train.head()}\")\n",
    "\n",
    "    # Categorical encoding\n",
    "    try:\n",
    "        cbe = CatBoostEncoder(cols=categorical_columns)\n",
    "        x_cat_train_encoded = cbe.fit_transform(x_cat_train, y_train)\n",
    "        x_cat_test_encoded = cbe.transform(x_cat_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during CatBoostEncoder transformation: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Combine numerical and encoded categorical features\n",
    "    X_train_processed = np.concatenate([x_num_train, x_cat_train_encoded.values], axis=1)\n",
    "    X_test_processed = np.concatenate([x_num_test, x_cat_test_encoded.values], axis=1)\n",
    "\n",
    "    return X_train_processed, X_test_processed, y_train.values, y_test.values\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    \"AdaBoostClassifier\": {\n",
    "        \"name\": AdaBoostClassifier,\n",
    "        \"params\": {\n",
    "            \"n_estimators\": tune.qrandint(10, 200, 10),\n",
    "            \"learning_rate\": tune.qloguniform(0.01, 2.0, 0.01),\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"name\": RandomForestClassifier,\n",
    "        \"params\": {\n",
    "            \"n_estimators\": tune.qrandint(50, 500, 50),\n",
    "            \"max_depth\": tune.qrandint(2, 20, 2),\n",
    "            \"min_samples_split\": tune.quniform(0.01, 0.5, 0.01),\n",
    "            \"min_samples_leaf\": tune.quniform(0.01, 0.5, 0.01)\n",
    "        }\n",
    "    },\n",
    "    \"GaussianProcessClassifier\": {\n",
    "        \"name\": GaussianProcessClassifier,\n",
    "        \"params\": {\n",
    "            \"kernel\": tune.choice([1.0 * RBF(length_scale) for length_scale in [1.0, 2.0, 3.0, 5.0]]),\n",
    "            \"max_iter_predict\": tune.qrandint(50, 500, 50)\n",
    "        }\n",
    "    },\n",
    "    \"GaussianNB\": {\n",
    "        \"name\": GaussianNB,\n",
    "        \"params\": {\n",
    "            \"var_smoothing\": tune.qloguniform(1e-9, 1e-3, 1e-9)\n",
    "        }\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"name\": KNeighborsClassifier,\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": tune.randint(3, 20),\n",
    "            \"weights\": tune.choice([\"uniform\", \"distance\"]),\n",
    "            \"metric\": tune.choice([\"euclidean\", \"manhattan\", \"minkowski\"])\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"name\": MLPClassifier,\n",
    "        \"params\": {\n",
    "            \"hidden_layer_sizes\": tune.choice([(50,), (100,), (50, 50), (100, 50)]),\n",
    "            \"activation\": tune.choice([\"logistic\", \"tanh\", \"relu\"]),\n",
    "            \"solver\": \"adam\",\n",
    "            \"alpha\": tune.qloguniform(1e-5, 1e-1, 1e-5),\n",
    "            \"learning_rate\": tune.choice([\"constant\", \"invscaling\", \"adaptive\"])\n",
    "        }\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"name\": SVC,\n",
    "        \"params\": {\n",
    "            \"C\": tune.qloguniform(1e-5, 1e2, 1e-5),\n",
    "            \"kernel\": tune.choice([\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "            \"gamma\": tune.choice([\"scale\", \"auto\"]),\n",
    "            \"degree\": tune.randint(2, 5)  # for poly kernel\n",
    "        }\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"name\": DecisionTreeClassifier,\n",
    "        \"params\": {\n",
    "            \"criterion\": tune.choice([\"gini\", \"entropy\"]),\n",
    "            \"max_depth\": tune.qrandint(2, 20, 2),\n",
    "            \"min_samples_split\": tune.quniform(0.01, 0.5, 0.01),\n",
    "            \"min_samples_leaf\": tune.quniform(0.01, 0.5, 0.01)\n",
    "        }\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"name\": LogisticRegression,\n",
    "        \"params\": {\n",
    "            \"C\": tune.qloguniform(1e-5, 1e2, 1e-5),\n",
    "            \"penalty\": tune.choice([\"l1\", \"l2\"]),\n",
    "            \"max_iter\": tune.qrandint(50, 500, 50),\n",
    "            \"solver\": \"liblinear\", \n",
    "        }\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"name\": XGBClassifier,\n",
    "        \"params\": {\n",
    "            \"n_estimators\": tune.qrandint(50, 500, 50),\n",
    "            \"max_depth\": tune.qrandint(2, 20, 2),\n",
    "            \"learning_rate\": tune.qloguniform(0.01, 2.0, 0.01),\n",
    "            \"gamma\": tune.quniform(0.01, 0.5, 0.01),\n",
    "            \"min_child_weight\": tune.quniform(0.01, 0.5, 0.01),\n",
    "            \"subsample\": tune.quniform(0.1, 1.0, 0.1),\n",
    "            \"colsample_bytree\": tune.quniform(0.5, 1.0, 0.1),\n",
    "            \"reg_alpha\": tune.qloguniform(1e-5, 1e2, 1e-5),\n",
    "            \"reg_lambda\": tune.qloguniform(1e-5, 1e2, 1e-5),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Trainable function to use with Ray Tune\n",
    "def train_model(config, data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    classifier_name = config[\"classifier_name\"]\n",
    "    classifier_class = search_space[classifier_name][\"name\"]\n",
    "    params = config[\"params\"]\n",
    "    \n",
    "    # Initialize and train the classifier\n",
    "    model = classifier_class(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    # Report the results to Tune\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "# Main function to run trials for each classifier\n",
    "def run_tune_trials(df, num_cols, cat_cols, target_col, search_space, n_trials=50, time_budget_s=None):\n",
    "    all_results = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = preprocess_df(df, num_cols, cat_cols, target_col)\n",
    "    \n",
    "    for classifier_name, classifier_info in search_space.items():\n",
    "        config = {\n",
    "            \"classifier_name\": classifier_name,\n",
    "            \"params\": classifier_info[\"params\"]\n",
    "        }\n",
    "        \n",
    "        trainable = tune.with_parameters(train_model, data=(X_train, X_test, y_train, y_test))\n",
    "        # Run Tune for the classifier\n",
    "        tuner = tune.Tuner(\n",
    "            trainable = trainable,\n",
    "            param_space=config,\n",
    "            tune_config=tune.TuneConfig(\n",
    "                metric=\"accuracy\",\n",
    "                mode=\"max\",\n",
    "                num_samples=n_trials,\n",
    "                search_alg=OptunaSearch(),\n",
    "                time_budget_s=time_budget_s\n",
    "            )\n",
    "        )\n",
    "\n",
    "        tuner.fit()\n",
    "\n",
    "        # Collect results for this classifier\n",
    "        results = tuner.get_results().get_dataframe()\n",
    "        results[\"classifier_name\"] = classifier_name\n",
    "        all_results.append(results)\n",
    "    \n",
    "    # Combine all results into a single DataFrame\n",
    "    final_results = pd.concat(all_results, ignore_index=True)\n",
    "    return final_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"jainaru/thyroid-disease-data\")\n",
    "path = f\"{path}/Thyroid_Diff.csv\"\n",
    "data = pd.read_csv(path) #uses pandas to read the CSV file into dataframe named 'data'\n",
    "data = data.sample(frac=1, random_state=1) #randomly shuffles the rows in the 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns for better understanding\n",
    "data.rename(columns={'Hx Smoking': 'Smoking History',\n",
    "                   'Hx Radiothreapy': 'Radiotherapy History',\n",
    "                   'Pathology': 'Types of Thyroid Cancer (Pathology)',\n",
    "                   'T': 'Tumor',\n",
    "                   'N': 'Lymph Nodes',\n",
    "                   'M': 'Cancer Metastasis',\n",
    "                  'Response' : 'Treatment Response'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Age**: The age of the patient at the time of diagnosis or treatment.\n",
    "- **Gender**: The gender of the patient (male or female).\n",
    "- **Smoking**: Whether the patient is a smoker or not.\n",
    "- **Hx Smoking**: Smoking history of the patient (e.g., whether they have ever smoked).\n",
    "- **Hx Radiotherapy**: History of radiotherapy treatment for any condition.\n",
    "- **Thyroid Function**: The status of thyroid function, possibly indicating if there are any abnormalities.\n",
    "- **Physical Examination**: Findings from a physical examination of the patient, which may include palpation of the thyroid gland and surrounding structures.\n",
    "- **Adenopathy**: Presence or absence of enlarged lymph nodes (adenopathy) in the neck region.\n",
    "- **Pathology**: Specific types of thyroid cancer as determined by pathology examination of biopsy samples.\n",
    "- **Focality**: Whether the cancer is unifocal (limited to one location) or multifocal (present in multiple locations).\n",
    "- **Risk**: The risk category of the cancer based on various factors, such as tumor size, extent of spread, and histological type.\n",
    "- **T**: Target Variable; Tumor classification based on its size and extent of invasion into nearby structures.\n",
    "- **N**: Nodal classification indicating the involvement of lymph nodes.\n",
    "- **M**: Metastasis classification indicating the presence or absence of distant metastases.\n",
    "- **Stage**: The overall stage of the cancer, typically determined by combining T, N, and M classifications.\n",
    "- **Response**: Response to treatment, indicating whether the cancer responded positively, negatively, or remained stable after treatment.\n",
    "- **Recurred**: Indicates whether the cancer has recurred after initial treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Use: \n",
    "1. Replace \"df = make_rand_df()\" with your own dataframe.\n",
    "2. Replace num_cols with the names of your numerical columns e.g. P/E ratio etc.\n",
    "3. Replace cat_cols with your categorical parameters e.g. Sector, Industry etc. (obv not that since thats what you're trying to predict)\n",
    "4. Replace target_col with the name of the column you're trying to predict e.g. Sector \n",
    "5. n_trials is the number of trials to run per estimator, and time_budget_s is the time budget in seconds for **all trials for that model**. \n",
    "\n",
    "I'd be pretty shocked if XGBoost doesn't win, as that's literally the only thing used in practice. If you're getting like 99-100% accuracy, you're probably overfitting and would want to switch to cross validation (if you're familiar). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-17 00:00:04</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:05.46        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.5/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">    params/colsample_byt\n",
       "ree</th><th style=\"text-align: right;\">  params/gamma</th><th style=\"text-align: right;\">  params/learning_rate</th><th style=\"text-align: right;\">  params/max_depth</th><th style=\"text-align: right;\">     params/min_child_wei\n",
       "ght</th><th style=\"text-align: right;\">  params/n_estimators</th><th style=\"text-align: right;\">  params/reg_alpha</th><th style=\"text-align: right;\">  params/reg_lambda</th><th style=\"text-align: right;\">  params/subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">      f1</th><th style=\"text-align: right;\">  precision</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_023fec78</td><td>TERMINATED</td><td>127.0.0.1:33536</td><td style=\"text-align: right;\">0.7</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">             0.0114691</td><td style=\"text-align: right;\">                12</td><td style=\"text-align: right;\">0.36</td><td style=\"text-align: right;\">                   50</td><td style=\"text-align: right;\">       7.65356e-05</td><td style=\"text-align: right;\">          0.0960428</td><td style=\"text-align: right;\">               0.2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.100197</td><td style=\"text-align: right;\">  0.571429</td><td style=\"text-align: right;\">0.482468</td><td style=\"text-align: right;\">   0.433766</td></tr>\n",
       "<tr><td>train_model_9582621b</td><td>TERMINATED</td><td>127.0.0.1:33553</td><td style=\"text-align: right;\">0.6</td><td style=\"text-align: right;\">          0.34</td><td style=\"text-align: right;\">             0.164654 </td><td style=\"text-align: right;\">                14</td><td style=\"text-align: right;\">0.32</td><td style=\"text-align: right;\">                  350</td><td style=\"text-align: right;\">       1.99357e-05</td><td style=\"text-align: right;\">          0.0115786</td><td style=\"text-align: right;\">               0.7</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.162921</td><td style=\"text-align: right;\">  0.636364</td><td style=\"text-align: right;\">0.549996</td><td style=\"text-align: right;\">   0.491862</td></tr>\n",
       "<tr><td>train_model_1f72791c</td><td>TERMINATED</td><td>127.0.0.1:33567</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">          0.12</td><td style=\"text-align: right;\">             0.151839 </td><td style=\"text-align: right;\">                14</td><td style=\"text-align: right;\">0.41</td><td style=\"text-align: right;\">                  400</td><td style=\"text-align: right;\">       1.87639    </td><td style=\"text-align: right;\">          0.128636 </td><td style=\"text-align: right;\">               0.1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.133907</td><td style=\"text-align: right;\">  0.558442</td><td style=\"text-align: right;\">0.463575</td><td style=\"text-align: right;\">   0.4     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=33553)\u001b[0m /opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=33553)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "2024-11-17 00:00:04,778\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/freddieliang/ray_results/train_model_2024-11-16_23-59-59' in 0.0057s.\n",
      "2024-11-17 00:00:04,782\tINFO tune.py:1041 -- Total run time: 5.48 seconds (5.46 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>classifier_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>0.491862</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.601808</td>\n",
       "      <td>0.610189</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.571869</td>\n",
       "      <td>0.578355</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.538597</td>\n",
       "      <td>0.489121</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>MLPClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.561507</td>\n",
       "      <td>0.566731</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.584416</td>\n",
       "      <td>0.520784</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>MLPClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.584416</td>\n",
       "      <td>0.524790</td>\n",
       "      <td>0.523282</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.482468</td>\n",
       "      <td>0.433766</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.502411</td>\n",
       "      <td>0.455185</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.480821</td>\n",
       "      <td>0.438990</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.476829</td>\n",
       "      <td>0.440226</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.463575</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.443226</td>\n",
       "      <td>0.443414</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>MLPClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.457338</td>\n",
       "      <td>0.524041</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.414828</td>\n",
       "      <td>0.353305</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.414828</td>\n",
       "      <td>0.353305</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.384039</td>\n",
       "      <td>0.320908</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>0.414559</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.358898</td>\n",
       "      <td>0.315505</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.326610</td>\n",
       "      <td>0.260552</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.318116</td>\n",
       "      <td>0.252905</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.381698</td>\n",
       "      <td>0.453942</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.313754</td>\n",
       "      <td>0.252044</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.313754</td>\n",
       "      <td>0.252044</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.218473</td>\n",
       "      <td>0.151796</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.218473</td>\n",
       "      <td>0.151796</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.218473</td>\n",
       "      <td>0.151796</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.306747</td>\n",
       "      <td>0.375308</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.330947</td>\n",
       "      <td>0.381325</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy        f1  precision    recall            classifier_name\n",
       "28  0.636364  0.549996   0.491862  0.636364              XGBClassifier\n",
       "9   0.636364  0.601808   0.610189  0.636364                 GaussianNB\n",
       "10  0.623377  0.571869   0.578355  0.623377                 GaussianNB\n",
       "17  0.610390  0.538597   0.489121  0.610390              MLPClassifier\n",
       "11  0.610390  0.561507   0.566731  0.610390                 GaussianNB\n",
       "16  0.584416  0.520784   0.471503  0.584416              MLPClassifier\n",
       "25  0.584416  0.524790   0.523282  0.584416         LogisticRegression\n",
       "27  0.571429  0.482468   0.433766  0.571429              XGBClassifier\n",
       "22  0.571429  0.502411   0.455185  0.571429     DecisionTreeClassifier\n",
       "6   0.571429  0.480821   0.438990  0.571429  GaussianProcessClassifier\n",
       "7   0.571429  0.476829   0.440226  0.571429  GaussianProcessClassifier\n",
       "29  0.558442  0.463575   0.400000  0.558442              XGBClassifier\n",
       "15  0.545455  0.443226   0.443414  0.545455              MLPClassifier\n",
       "12  0.532468  0.457338   0.524041  0.532468       KNeighborsClassifier\n",
       "4   0.519481  0.414828   0.353305  0.519481     RandomForestClassifier\n",
       "5   0.519481  0.414828   0.353305  0.519481     RandomForestClassifier\n",
       "8   0.493506  0.384039   0.320908  0.493506  GaussianProcessClassifier\n",
       "14  0.493506  0.431107   0.414559  0.493506       KNeighborsClassifier\n",
       "13  0.480519  0.358898   0.315505  0.480519       KNeighborsClassifier\n",
       "18  0.467532  0.326610   0.260552  0.467532                        SVC\n",
       "3   0.441558  0.318116   0.252905  0.441558     RandomForestClassifier\n",
       "2   0.428571  0.381698   0.453942  0.428571         AdaBoostClassifier\n",
       "23  0.415584  0.313754   0.252044  0.415584     DecisionTreeClassifier\n",
       "21  0.415584  0.313754   0.252044  0.415584     DecisionTreeClassifier\n",
       "20  0.389610  0.218473   0.151796  0.389610                        SVC\n",
       "26  0.389610  0.218473   0.151796  0.389610         LogisticRegression\n",
       "19  0.389610  0.218473   0.151796  0.389610                        SVC\n",
       "0   0.363636  0.306747   0.375308  0.363636         AdaBoostClassifier\n",
       "1   0.350649  0.330947   0.381325  0.350649         AdaBoostClassifier\n",
       "24  0.077922  0.011266   0.006072  0.077922         LogisticRegression"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=33567)\u001b[0m /opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\u001b[36m(train_model pid=33567)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Map T column to numeric values\n",
    "tumor_mapping = {\n",
    "    'T1a': 0, 'T1b': 1, 'T2': 2, \n",
    "    'T3a': 3, 'T3b': 4, 'T4a': 5, 'T4b': 6\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "data['Tumor'] = data['Tumor'].map(tumor_mapping)\n",
    "\n",
    "# Prepare the dataset for training\n",
    "df = data.drop(['Lymph Nodes', 'Cancer Metastasis', 'Treatment Response', 'Stage', 'Recurred'], axis=1)\n",
    "num_cols = ['Age']\n",
    "cat_cols = [\n",
    "    'Gender', 'Smoking', 'Smoking History', 'Radiotherapy History', 'Thyroid Function',\n",
    "    'Physical Examination', 'Adenopathy', 'Types of Thyroid Cancer (Pathology)', \n",
    "    'Focality', 'Risk'\n",
    "]\n",
    "target_col = \"Tumor\"\n",
    "\n",
    "# Pass the updated dataset into your model pipeline\n",
    "final_results = run_tune_trials(df, num_cols, cat_cols, target_col, search_space, n_trials=3, time_budget_s=100)\n",
    "final_results[[col for col in final_results.columns if col in [\"classifier_name\", \"accuracy\", \"f1\", \"precision\", \"recall\"]]].sort_values(\"accuracy\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
